{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqg4y371CM7X"
   },
   "source": [
    "# Fine-tuning BERT for Sentiment Analysis for Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31OW0dhozvli"
   },
   "source": [
    "## A1. Load Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_lTXsMK3sNYr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u07WRKnxsX96"
   },
   "source": [
    "## A2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_tOJXeR9sx57"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\",index_col = 'id')\n",
    "test_df = pd.read_csv(\"test.csv\",index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YkvxmkoXwQGk"
   },
   "outputs": [],
   "source": [
    "train_df_copy = train_df.copy()\n",
    "train_df_copy = train_df_copy.filter(items=['id', 'text', 'target']) \n",
    "test_df_copy = test_df.copy()\n",
    "test_df_copy = test_df_copy.filter(items=['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "O_Pf5u-Fy2Y5",
    "outputId": "90ac7b20-1f54-4cc8-88c8-8efd0a229cd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-917df354-fc6f-4b0f-bd38-02c2b5cd5d9c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-917df354-fc6f-4b0f-bd38-02c2b5cd5d9c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-917df354-fc6f-4b0f-bd38-02c2b5cd5d9c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-917df354-fc6f-4b0f-bd38-02c2b5cd5d9c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 text  target\n",
       "id                                                           \n",
       "1   Our Deeds are the Reason of this #earthquake M...       1\n",
       "4              Forest fire near La Ronge Sask. Canada       1\n",
       "5   All residents asked to 'shelter in place' are ...       1\n",
       "6   13,000 people receive #wildfires evacuation or...       1\n",
       "7   Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "6wlARjK1y4gN",
    "outputId": "6fcd9d22-9f42-4c9a-a855-ab1d95667f16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5a14993c-8438-4791-9519-4ba226001970\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a14993c-8438-4791-9519-4ba226001970')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5a14993c-8438-4791-9519-4ba226001970 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5a14993c-8438-4791-9519-4ba226001970');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 text\n",
       "id                                                   \n",
       "0                  Just happened a terrible car crash\n",
       "2   Heard about #earthquake is different cities, s...\n",
       "3   there is a forest fire at spot pond, geese are...\n",
       "9            Apocalypse lighting. #Spokane #wildfires\n",
       "11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp-vfxKZvl6M"
   },
   "source": [
    "Randomly split the trainning data into 2 sets; train set with 90% of the data and validation set with 10% of the data. We will conduct hyperparameter tuning via cross-validation on the train set and use the validation set to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X4HKAFTbvMwI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df.text.values\n",
    "y = train_df.target.values\n",
    "\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X79dYY3sxDCi"
   },
   "source": [
    "## A3. Set up GPU for training using Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi1CoEOL1puh"
   },
   "source": [
    "Google Colab offers free GPUs and TPUs. Since we'll be training a large neural network it's best to utilize these features.\n",
    "\n",
    "A GPU can be added by going to the menu and selecting:\n",
    "\n",
    "`Runtime -> Change runtime type -> Hardware accelerator: GPU`\n",
    "\n",
    "Then we need to run the following cell to specify the GPU as the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7hxtI4l0SUJ",
    "outputId": "1eb94abd-95d6-44db-de66-a8f776db6ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeljUmsqAUpt"
   },
   "source": [
    "### B1. Data Cleaning: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_OzXFcfCBOa"
   },
   "source": [
    "We will remove punctuations, stopwords, whitespace and special symbols that do not contribute much to the sentence's meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98rwWTSw_dEI",
    "outputId": "28e5eada-e054-41dd-8cb4-6e8e8a91dc33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8jpfxygCvww"
   },
   "source": [
    "### B2. Data Transformation: TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbD689AMC-aB"
   },
   "source": [
    "In information retrieval, **TF-IDF**, short for **term frequency–inverse document frequency**, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. We will use TF-IDF to vectorize our text data before feeding them to machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOQ3X7hPDYhn",
    "outputId": "65b2ae92-42c5-47b2-a164-a9f4d9611177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 1.33 s, total: 13.1 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne-eoqM4Muna"
   },
   "source": [
    "To evaluate the performance of our model, we will calculate the accuracy rate and the AUC score of our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qS2gb-9mJK2w"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEPPYHa62JXF"
   },
   "source": [
    "# Fine-tuning Bidirectional Encoder Representations from Transformers (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYJRzWI73eBJ"
   },
   "source": [
    "## C1. Install the Hugging Face Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yxv-EJ2j31Iv"
   },
   "source": [
    "The Hugging Face transformer library contains the PyTorch implementation of state-of-the-art NLP models including BERT (from Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFiv8WGl4p40",
    "outputId": "8cbea599-04c1-498d-c3ab-72f65a4ce649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers==2.8.0\n",
      "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "\u001b[K     |████████████████████████████████| 563 kB 25.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 56.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.8.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 56.5 MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 53.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2022.6.2)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.24.61-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 63.0 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.61\n",
      "  Downloading botocore-1.27.61-py3-none-any.whl (9.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1 MB 53.7 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.61->boto3->transformers==2.8.0) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 75.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.61->boto3->transformers==2.8.0) (1.15.0)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 76.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=dac6e9bf48c8ab938cd8311cf0f811d1ab876e20c3e7ad4c1ebef9e3687ec985\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed boto3-1.24.61 botocore-1.27.61 jmespath-1.0.1 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.5.2 transformers-2.8.0 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4sXctSh4sq0"
   },
   "source": [
    "## C2. Tokenization and Input Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygbZpK6qbIYE"
   },
   "source": [
    "Before tokenizing our text, we peform preprocessing on our text such as removing entity mentions(eg. @united) and other special character. The level of processing is much less than previous approaches as BERT was trained with entire sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4L_Rc7l4bgzJ"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    #Remove puncutation\n",
    "    table = str.maketrans(\"\",\"\",string.punctuation)\n",
    "    text = text.translate(table)\n",
    "\n",
    "    #Remove html links\n",
    "    url = re.compile(r'http?://\\S+|www\\.\\S+')\n",
    "    text = url.sub(r'',text)\n",
    "\n",
    "    #Remove emoji\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyYmHR8McE0r",
    "outputId": "b98fa627-57ef-4fbc-9b2d-a215fddd8a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Processed:  Our Deeds are the Reason of this earthquake May ALLAH Forgive us all\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3acv6s95YYr"
   },
   "source": [
    "### C3. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1fRHtdU5dEn"
   },
   "source": [
    "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\n",
    "\n",
    "In addition, we are required to add special tokens to the start and end of each sentence, pad & truncate all sentences to a single constant length, and explicitly specify what are padding tokens with the \"attention mask\".\n",
    "\n",
    "The `encode_plus` method of BERT tokenizer will:\n",
    "\n",
    "(1) split our text into tokens,\n",
    "\n",
    "(2) add the special `[CLS]` and `[SEP]` tokens, and\n",
    "\n",
    "(3) convert these tokens into indexes of the tokenizer vocabulary,\n",
    "\n",
    "(4) pad or truncate sentences to max length, and\n",
    "\n",
    "(5) create attention mask.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e58f735f0ee9456d8f0611004a293adb",
      "d705feca0f3f42668d6bec652e1a79b7",
      "4e5a5670d9ee433c9ec2edb1ec9a855f",
      "2b5f5b901af344de8d8993b920a008fb",
      "b6dab18f47a244d88a330f0021dcbae3",
      "9f666b7390cd4c84a9a46a21cb592270",
      "3de5a467fe2e45eab8d1120f8ec7e4df",
      "3ec065f28af74c7aa634d9388ed44b40",
      "371fa52911544ce396dd6bf128b0d154",
      "00c685286ece487993abdb05db9bc6a5",
      "a74ff3fcb03a4ab0885ace7541e13a0b"
     ]
    },
    "id": "yDAfbCle59tP",
    "outputId": "086f63ae-dd56-4eaa-e0f4-b92cafbf53fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58f735f0ee9456d8f0611004a293adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNE9oASMZ1bN"
   },
   "source": [
    "Before tokenizing, we need to specify the maximum length of our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrbvKGNAlMtt",
    "outputId": "d0b4a460-9970-46e2-887c-36272c7e7fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  84\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train data and test data\n",
    "all_tweets = np.concatenate([train_df.text.values, test_df.text.values])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpdjBB9fmbu2"
   },
   "source": [
    "Now let's tokenize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTlQzTzAfCy7",
    "outputId": "da9a8b38-95ec-4c1a-d9b6-0448756a276c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Token IDs:  [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZU8t5VNfvhY"
   },
   "source": [
    "### C4. Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoHdl3gFgMZY"
   },
   "source": [
    "We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xHuYEc61gcGL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSRAga-yj17q"
   },
   "source": [
    "## D. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoOdsDgG8b_Z"
   },
   "source": [
    "### D1. Create BertClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA_yESCl5nuK"
   },
   "source": [
    "BERT-base consists of 12 transformer layers, each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the `[CLS]` token is used as the features of the sequence to feed a classifier.\n",
    "\n",
    "The `transformers` library has the [`BertForSequenceClassification`](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification) class which is designed for classification tasks. However, we will create a new class so we can specify our own choice of classifiers.\n",
    "\n",
    "Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the `[CLS]` token and a single-hidden-layer feed-forward neural network as our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YK41aBFSj5jK",
    "outputId": "4b0d9f75-1fe5-4f8e-c642-1f8d71cddbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 µs, sys: 0 ns, total: 42 µs\n",
      "Wall time: 45.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwNrCgPh-yR7"
   },
   "source": [
    "### D2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6iOXiN8-8gc"
   },
   "source": [
    "To fine-tune our Bert Classifier, we need to create an optimizer. The authors recommend following hyper-parameters:\n",
    "\n",
    "- Batch size: 16 or 32\n",
    "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
    "- Number of epochs: 2, 3, 4\n",
    "\n",
    "Huggingface provided the [run_glue.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109) script, an examples of implementing the `transformers` library. In the script, the AdamW optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JX7su7Q_269U"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41DRNjv4B0Ow"
   },
   "source": [
    "### D3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYU-GQRZG0y8"
   },
   "source": [
    "We will train our Bert Classifier for 4 epochs. In each epoch, we will train our model and evaluate its performance on the validation set. In more details, we will:\n",
    "\n",
    "Training:\n",
    "- Unpack our data from the dataloader and load the data onto the GPU\n",
    "- Zero out gradients calculated in the previous pass\n",
    "- Perform a forward pass to compute logits and loss\n",
    "- Perform a backward pass to compute gradients (`loss.backward()`)\n",
    "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "- Update the model's parameters (`optimizer.step()`)\n",
    "- Update the learning rate (`scheduler.step()`)\n",
    "\n",
    "Evaluation:\n",
    "- Unpack our data and load onto the GPU\n",
    "- Forward pass\n",
    "- Compute loss and accuracy rate over the validation set\n",
    "\n",
    "The script below is commented with the details of our training and evaluation loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Xy4HkhyECibW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSfTy9LqiFD-"
   },
   "source": [
    "Now, let's start training our BertClassifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 845,
     "referenced_widgets": [
      "56d5a78d69a5480383459434dca31136",
      "8b48e415d7ad431894d71eafe67e4f95",
      "5a2785968b634e86b93b1251ffcdbfc8",
      "e0486a8c824946558b4c4b09a9fffd4e",
      "e4e6301a8fa74d0183ca73f38390f6ae",
      "548e1b4e199c4b1eb93dd1ab2016a342",
      "82578ebc748b4e50a35de6e782501a60",
      "0b6b6ee28cc549af86c80bfc9c64903c",
      "14f788bf541a4469b8d2cfb476d0d9a5",
      "07fa07bf7cef4a51a6e42357c92942d9",
      "2fa04a5a66cd47a49e8146eef49399d1",
      "5ae129979fce4686b94d6485a8e6bb4f",
      "173502dffd2d43a3a5b36adf0010284b",
      "a1f82f5b11c6446e9b0d826a5a9a0c73",
      "d65469a7ec9d438e8f4e54967222f1b1",
      "ad047048b8204c0eaa520ffc3586a66f",
      "074bbac89ff54e129e01bde44066d8c0",
      "12a935ceb1e549b99940be4f3f945737",
      "79fe905aa439461ba891e1c0416cb77c",
      "bd9375f4386348838bab9df7ea0599fe",
      "3cca17101cdd4bd789489ce63e8b47f7",
      "08839773792646429722e45cd0ed890b"
     ]
    },
    "id": "wfYw7dJ0U0v6",
    "outputId": "0a44788a-4457-4ad6-b5cb-1d1413ab8ae1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d5a78d69a5480383459434dca31136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae129979fce4686b94d6485a8e6bb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |   20    |   0.579694   |     -      |     -     |   9.66   \n",
      "   1    |   40    |   0.463997   |     -      |     -     |   6.27   \n",
      "   1    |   60    |   0.426793   |     -      |     -     |   6.34   \n",
      "   1    |   80    |   0.440728   |     -      |     -     |   6.47   \n",
      "   1    |   100   |   0.419770   |     -      |     -     |   6.48   \n",
      "   1    |   120   |   0.407389   |     -      |     -     |   6.51   \n",
      "   1    |   140   |   0.384483   |     -      |     -     |   6.53   \n",
      "   1    |   160   |   0.413384   |     -      |     -     |   6.66   \n",
      "   1    |   180   |   0.431401   |     -      |     -     |   6.69   \n",
      "   1    |   200   |   0.430120   |     -      |     -     |   6.70   \n",
      "   1    |   214   |   0.401293   |     -      |     -     |   4.50   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.437921   |  0.426313  |   82.20   |   75.57  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.313943   |     -      |     -     |   7.22   \n",
      "   2    |   40    |   0.294178   |     -      |     -     |   6.95   \n",
      "   2    |   60    |   0.308993   |     -      |     -     |   7.03   \n",
      "   2    |   80    |   0.307236   |     -      |     -     |   7.09   \n",
      "   2    |   100   |   0.322581   |     -      |     -     |   7.19   \n",
      "   2    |   120   |   0.306080   |     -      |     -     |   7.22   \n",
      "   2    |   140   |   0.281535   |     -      |     -     |   7.26   \n",
      "   2    |   160   |   0.302280   |     -      |     -     |   7.19   \n",
      "   2    |   180   |   0.277308   |     -      |     -     |   7.11   \n",
      "   2    |   200   |   0.290242   |     -      |     -     |   7.05   \n",
      "   2    |   214   |   0.288551   |     -      |     -     |   4.64   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.299726   |  0.439817  |   82.72   |   78.83  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5ostg9kPlra"
   },
   "source": [
    "### D4. Model evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIlSTDA7Z9DF"
   },
   "source": [
    "The prediction step is similar to the evaluation step that we did in the training loop, but simpler. We will perform a forward pass to compute logits and apply softmax function to calculate probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "V5_w4erqGzpe"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "kcmj5s0eRMUh",
    "outputId": "1d10ac70-29bf-4b1d-ed22-f9fa514018a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9592\n",
      "Accuracy: 90.94%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "val_probs = bert_predict(bert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(val_probs, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT classifier achieves a 0.95 AUC score and 90.94% accuracy rate on the validation set. This is a significant prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-PvgNNsF8DL"
   },
   "source": [
    "### D5. Metrics for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sklearn metrics library to compute common model metrics such as accuracy score, f1_score, precision, sensitiviy and specificity and plot the confusion metrix to determine the model performance\n",
    "\n",
    "The threshold we will use is 0.9, meaning that tweets with a predicted probability greater than 90% will be predicted positive. This value is very high compared to the default 0.5 threshold and will give a safer predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "7jCNz--oE22E",
    "outputId": "be814223-d124-44a4-f04c-fae40ec5d1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_accuracy: 0.8700787401574803\n",
      "model_precision: 0.7369942196531792\n",
      "model_auc: 0.8936085097952559\n",
      "model_f1score: 0.8374384236453202\n",
      "sensitivity 0.9695817490494296\n",
      "specificity 0.8176352705410822\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9d2261e0-87fe-4214-a5a7-cd16919a4789\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Y=0</th>\n",
       "      <th>True Y=1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Y=0</th>\n",
       "      <td>408</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Y=1</th>\n",
       "      <td>8</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d2261e0-87fe-4214-a5a7-cd16919a4789')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9d2261e0-87fe-4214-a5a7-cd16919a4789 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9d2261e0-87fe-4214-a5a7-cd16919a4789');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               True Y=0  True Y=1\n",
       "Predicted Y=0       408        91\n",
       "Predicted Y=1         8       255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "def churn_eval_metrics(Y_pred, Y_test):\n",
    "    model_acc = accuracy_score(Y_test, Y_pred)\n",
    "    model_prec = precision_score(Y_test, Y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label = 1)\n",
    "    model_auc = auc(fpr,tpr)\n",
    "\n",
    "    model_f1score = f1_score(Y_test, Y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "\n",
    "    print(\"model_accuracy:\", model_acc)\n",
    "    print(\"model_precision:\",model_prec)\n",
    "    print(\"model_auc:\", model_auc)\n",
    "    print(\"model_f1score:\",model_f1score)\n",
    "    print(\"sensitivity\", sensitivity)\n",
    "    print(\"specificity\", specificity)\n",
    "\n",
    "    cm = pd.DataFrame(confusion_matrix(Y_test,Y_pred))\n",
    "    cm.columns = ['True Y=0','True Y=1']\n",
    "    cm.index = ['Predicted Y=0','Predicted Y=1']\n",
    "    display(cm)\n",
    "\n",
    "\n",
    "threshold = 0.9\n",
    "y_preds = np.where(val_probs[:, 1] > threshold, 1, 0)\n",
    "churn_eval_metrics(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5DW6grRmfT-"
   },
   "source": [
    "### D6. Train Our Model on the Entire Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkMK5VqJJvSO",
    "outputId": "620deb70-0a40-4291-fbcc-b81e01bcd703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.574707   |     -      |     -     |   7.25   \n",
      "   1    |   40    |   0.434186   |     -      |     -     |   6.97   \n",
      "   1    |   60    |   0.451314   |     -      |     -     |   7.05   \n",
      "   1    |   80    |   0.461613   |     -      |     -     |   7.15   \n",
      "   1    |   100   |   0.428167   |     -      |     -     |   7.23   \n",
      "   1    |   120   |   0.432531   |     -      |     -     |   7.30   \n",
      "   1    |   140   |   0.403390   |     -      |     -     |   7.28   \n",
      "   1    |   160   |   0.456332   |     -      |     -     |   7.20   \n",
      "   1    |   180   |   0.409390   |     -      |     -     |   7.10   \n",
      "   1    |   200   |   0.397747   |     -      |     -     |   7.07   \n",
      "   1    |   220   |   0.403300   |     -      |     -     |   7.04   \n",
      "   1    |   237   |   0.419971   |     -      |     -     |   5.93   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.289473   |     -      |     -     |   7.37   \n",
      "   2    |   40    |   0.277166   |     -      |     -     |   7.05   \n",
      "   2    |   60    |   0.292813   |     -      |     -     |   7.10   \n",
      "   2    |   80    |   0.287206   |     -      |     -     |   7.12   \n",
      "   2    |   100   |   0.351639   |     -      |     -     |   7.14   \n",
      "   2    |   120   |   0.335717   |     -      |     -     |   7.14   \n",
      "   2    |   140   |   0.299604   |     -      |     -     |   7.12   \n",
      "   2    |   160   |   0.299294   |     -      |     -     |   7.10   \n",
      "   2    |   180   |   0.296076   |     -      |     -     |   7.09   \n",
      "   2    |   200   |   0.266226   |     -      |     -     |   7.08   \n",
      "   2    |   220   |   0.327756   |     -      |     -     |   7.07   \n",
      "   2    |   237   |   0.221352   |     -      |     -     |   5.99   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q89oT0n3N0m6"
   },
   "source": [
    "## E Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sqk_CPwjN_W0"
   },
   "source": [
    "### E.1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzCpJBgWZYR_"
   },
   "source": [
    "Before making predictions on the test set, we need to redo processing and encoding steps done on the training data. We will use `preprocessing_for_bert` function to do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56QTDchdOHBL",
    "outputId": "48b2de67-6a06-4045-c59d-d12c22fcc834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test_df.text)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYv9lSXsQCZ2"
   },
   "source": [
    "### 4.2. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGx8h7yXRkfI",
    "outputId": "3606c84a-5d87-4554-972a-e00f0eace9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets predicted real distaster:  959\n"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "# Get predictions from the probabilities\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "\n",
    "# Number of tweets predicted non-negative\n",
    "print(\"Number of tweets predicted real distaster: \", preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "f9rd_TI7DGM3"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'id':test_df.index,'target':preds.reshape(-1,)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "N11ktoWqDL51"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of BERT-for-Sentiment-Analysis.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c685286ece487993abdb05db9bc6a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "074bbac89ff54e129e01bde44066d8c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07fa07bf7cef4a51a6e42357c92942d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08839773792646429722e45cd0ed890b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b6b6ee28cc549af86c80bfc9c64903c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12a935ceb1e549b99940be4f3f945737": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f788bf541a4469b8d2cfb476d0d9a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "173502dffd2d43a3a5b36adf0010284b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_074bbac89ff54e129e01bde44066d8c0",
      "placeholder": "​",
      "style": "IPY_MODEL_12a935ceb1e549b99940be4f3f945737",
      "value": "Downloading: 100%"
     }
    },
    "2b5f5b901af344de8d8993b920a008fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00c685286ece487993abdb05db9bc6a5",
      "placeholder": "​",
      "style": "IPY_MODEL_a74ff3fcb03a4ab0885ace7541e13a0b",
      "value": " 232k/232k [00:00&lt;00:00, 2.68MB/s]"
     }
    },
    "2fa04a5a66cd47a49e8146eef49399d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "371fa52911544ce396dd6bf128b0d154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3cca17101cdd4bd789489ce63e8b47f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3de5a467fe2e45eab8d1120f8ec7e4df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ec065f28af74c7aa634d9388ed44b40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5a5670d9ee433c9ec2edb1ec9a855f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec065f28af74c7aa634d9388ed44b40",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_371fa52911544ce396dd6bf128b0d154",
      "value": 231508
     }
    },
    "548e1b4e199c4b1eb93dd1ab2016a342": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56d5a78d69a5480383459434dca31136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b48e415d7ad431894d71eafe67e4f95",
       "IPY_MODEL_5a2785968b634e86b93b1251ffcdbfc8",
       "IPY_MODEL_e0486a8c824946558b4c4b09a9fffd4e"
      ],
      "layout": "IPY_MODEL_e4e6301a8fa74d0183ca73f38390f6ae"
     }
    },
    "5a2785968b634e86b93b1251ffcdbfc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b6b6ee28cc549af86c80bfc9c64903c",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14f788bf541a4469b8d2cfb476d0d9a5",
      "value": 433
     }
    },
    "5ae129979fce4686b94d6485a8e6bb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_173502dffd2d43a3a5b36adf0010284b",
       "IPY_MODEL_a1f82f5b11c6446e9b0d826a5a9a0c73",
       "IPY_MODEL_d65469a7ec9d438e8f4e54967222f1b1"
      ],
      "layout": "IPY_MODEL_ad047048b8204c0eaa520ffc3586a66f"
     }
    },
    "79fe905aa439461ba891e1c0416cb77c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82578ebc748b4e50a35de6e782501a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b48e415d7ad431894d71eafe67e4f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_548e1b4e199c4b1eb93dd1ab2016a342",
      "placeholder": "​",
      "style": "IPY_MODEL_82578ebc748b4e50a35de6e782501a60",
      "value": "Downloading: 100%"
     }
    },
    "9f666b7390cd4c84a9a46a21cb592270": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1f82f5b11c6446e9b0d826a5a9a0c73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79fe905aa439461ba891e1c0416cb77c",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd9375f4386348838bab9df7ea0599fe",
      "value": 440473133
     }
    },
    "a74ff3fcb03a4ab0885ace7541e13a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad047048b8204c0eaa520ffc3586a66f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6dab18f47a244d88a330f0021dcbae3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd9375f4386348838bab9df7ea0599fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d65469a7ec9d438e8f4e54967222f1b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cca17101cdd4bd789489ce63e8b47f7",
      "placeholder": "​",
      "style": "IPY_MODEL_08839773792646429722e45cd0ed890b",
      "value": " 440M/440M [00:07&lt;00:00, 55.8MB/s]"
     }
    },
    "d705feca0f3f42668d6bec652e1a79b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f666b7390cd4c84a9a46a21cb592270",
      "placeholder": "​",
      "style": "IPY_MODEL_3de5a467fe2e45eab8d1120f8ec7e4df",
      "value": "Downloading: 100%"
     }
    },
    "e0486a8c824946558b4c4b09a9fffd4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07fa07bf7cef4a51a6e42357c92942d9",
      "placeholder": "​",
      "style": "IPY_MODEL_2fa04a5a66cd47a49e8146eef49399d1",
      "value": " 433/433 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "e4e6301a8fa74d0183ca73f38390f6ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58f735f0ee9456d8f0611004a293adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d705feca0f3f42668d6bec652e1a79b7",
       "IPY_MODEL_4e5a5670d9ee433c9ec2edb1ec9a855f",
       "IPY_MODEL_2b5f5b901af344de8d8993b920a008fb"
      ],
      "layout": "IPY_MODEL_b6dab18f47a244d88a330f0021dcbae3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
